{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP12jnt/mdLELHfW9TZEnLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarchi-dot/deep-learning/blob/main/DL_lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Statement 1: Architecture Design Focus"
      ],
      "metadata": {
        "id": "Fizjw_HQhF1V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn5hHTdjg0Vr",
        "outputId": "0474304f-59e8-4d66-9765-e97eaf204e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/cnn_models\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "print(\"Models will be saved to:\", save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrXnR6kb5VNA",
        "outputId": "9be797bd-b3f1-43ba-d65e-86f2e628afd5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models will be saved to: /content/drive/MyDrive/cnn_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROBLEM STATEMENT 2\n",
        "# Imbalanced Dataset Handling"
      ],
      "metadata": {
        "id": "m4x8cMD0hwxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub imbalanced-learn umap-learn -q\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import kagglehub\n"
      ],
      "metadata": {
        "id": "VWkPm8ZSj6Yk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chest X-Ray Dataset\n",
        "chest_path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
        "\n",
        "# Flowers Dataset\n",
        "flower_path = kagglehub.dataset_download(\"alxmamaev/flowers-recognition\")\n",
        "\n",
        "print(\"Chest Dataset:\", chest_path)\n",
        "print(\"Flower Dataset:\", flower_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0KpWqPnn2td",
        "outputId": "04bc9f8f-935a-4dc9-cb84-408ca2091c3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'chest-xray-pneumonia' dataset.\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (1.0.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/alxmamaev/flowers-recognition?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 225M/225M [00:01<00:00, 136MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chest Dataset: /kaggle/input/chest-xray-pneumonia\n",
            "Flower Dataset: /root/.cache/kagglehub/datasets/alxmamaev/flowers-recognition/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n"
      ],
      "metadata": {
        "id": "57XoBF8Un2qI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flower_train = datasets.ImageFolder(\n",
        "    root=f\"{flower_path}/flowers\",\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "flower_loader = DataLoader(flower_train, batch_size=32, shuffle=True)\n",
        "\n",
        "print(\"Flower Classes:\", flower_train.classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL1sVwyUn2nY",
        "outputId": "d25d38a0-4896-435f-de08-b4a8742c39de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flower Classes: ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chest_train = datasets.ImageFolder(\n",
        "    root=f\"{chest_path}/chest_xray/train\",\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "chest_val = datasets.ImageFolder(\n",
        "    root=f\"{chest_path}/chest_xray/val\",\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "chest_test = datasets.ImageFolder(\n",
        "    root=f\"{chest_path}/chest_xray/test\",\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "print(\"Chest Classes:\", chest_train.classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaZ6gJtTn2ky",
        "outputId": "284ea6bc-bfa0-45a7-a84e-7fc9b5a098b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chest Classes: ['NORMAL', 'PNEUMONIA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SECTION B – DATA LEVEL TECHNIQUES"
      ],
      "metadata": {
        "id": "ZGqDkCZupd50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_weighted_sampler(dataset):\n",
        "    targets = [label for _, label in dataset]\n",
        "    class_counts = np.bincount(targets)\n",
        "    class_weights = 1. / class_counts\n",
        "    sample_weights = [class_weights[label] for label in targets]\n",
        "    sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "    return sampler\n",
        "\n",
        "flower_sampler = create_weighted_sampler(flower_train)\n",
        "chest_sampler = create_weighted_sampler(chest_train)\n",
        "\n",
        "flower_loader_os = DataLoader(flower_train, batch_size=32, sampler=flower_sampler)\n",
        "chest_loader_os = DataLoader(chest_train, batch_size=32, sampler=chest_sampler)\n"
      ],
      "metadata": {
        "id": "akdE4fafn2hz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def undersample_dataset(dataset):\n",
        "    targets = np.array([label for _, label in dataset])\n",
        "    min_count = min(np.bincount(targets))\n",
        "    indices = []\n",
        "\n",
        "    for cls in np.unique(targets):\n",
        "        cls_idx = np.where(targets == cls)[0]\n",
        "        np.random.shuffle(cls_idx)\n",
        "        indices.extend(cls_idx[:min_count])\n",
        "\n",
        "    return torch.utils.data.Subset(dataset, indices)\n",
        "\n",
        "flower_under = undersample_dataset(flower_train)\n",
        "chest_under = undersample_dataset(chest_train)\n",
        "\n",
        "flower_loader_us = DataLoader(flower_under, batch_size=32, shuffle=True)\n",
        "chest_loader_us = DataLoader(chest_under, batch_size=32, shuffle=True)\n"
      ],
      "metadata": {
        "id": "sxGYhDCKn2fF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_smote(model, loader):\n",
        "    model.eval()\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, target in loader:\n",
        "            images = images.cuda() if torch.cuda.is_available() else images\n",
        "            feat = model.features(images)\n",
        "            feat = torch.flatten(feat, 1)\n",
        "            features.append(feat.cpu().numpy())\n",
        "            labels.append(target.numpy())\n",
        "\n",
        "    X = np.vstack(features)\n",
        "    y = np.hstack(labels)\n",
        "\n",
        "    sm = SMOTE()\n",
        "    X_res, y_res = sm.fit_resample(X, y)\n",
        "\n",
        "    return X_res, y_res\n"
      ],
      "metadata": {
        "id": "vutGSkT1n2b8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALGORITHM LEVEL TECHNIQUES"
      ],
      "metadata": {
        "id": "S_dpSK8dpoJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_class_weights(dataset):\n",
        "    targets = [label for _, label in dataset]\n",
        "    counts = np.bincount(targets)\n",
        "    weights = 1.0 / torch.tensor(counts, dtype=torch.float)\n",
        "    return weights\n",
        "\n",
        "flower_weights = get_class_weights(flower_train)\n",
        "chest_weights = get_class_weights(chest_train)\n",
        "\n",
        "criterion_flower_weighted = nn.CrossEntropyLoss(weight=flower_weights)\n",
        "criterion_chest_weighted = nn.CrossEntropyLoss(weight=chest_weights)\n"
      ],
      "metadata": {
        "id": "efyqMbIrn2Y4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CostSensitiveLoss(nn.Module):\n",
        "    def __init__(self, class_weights):\n",
        "        super().__init__()\n",
        "        self.weights = class_weights\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        ce = nn.CrossEntropyLoss(reduction='none')(outputs, targets)\n",
        "        weighted = ce * self.weights[targets]\n",
        "        return weighted.mean()\n"
      ],
      "metadata": {
        "id": "uET-adByj6HK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_with_threshold(model, loader, threshold=0.4):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.cuda() if torch.cuda.is_available() else images\n",
        "            outputs = torch.softmax(model(images), dim=1)\n",
        "            preds = (outputs[:,1] > threshold).int()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    return classification_report(all_labels, all_preds)\n"
      ],
      "metadata": {
        "id": "5loVhyGXj6Dn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATION"
      ],
      "metadata": {
        "id": "kTDYNr8Fpxnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, target in loader:\n",
        "            images = images.cuda() if torch.cuda.is_available() else images\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            preds.extend(predicted.cpu().numpy())\n",
        "            labels.extend(target.numpy())\n",
        "\n",
        "    print(classification_report(labels, preds))\n",
        "    print(\"Balanced Accuracy:\", balanced_accuracy_score(labels, preds))\n",
        "    print(\"Macro F1:\", f1_score(labels, preds, average='macro'))\n"
      ],
      "metadata": {
        "id": "RpBCtrfmj6Ap"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics thop -q\n",
        "\n",
        "import time\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
        "from sklearn.metrics import classification_report\n",
        "from torchmetrics.functional import accuracy\n",
        "from thop import profile\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud-3hCvDytSl",
        "outputId": "407ab72f-0909-4eee-ae53-87b48bd7948b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m983.0/983.2 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "def get_resnet(num_classes):\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "def get_efficientnet(num_classes):\n",
        "    model = models.efficientnet_b0(pretrained=True)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "qiPnUdyyytPF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=5):\n",
        "    model.to(device)\n",
        "    train_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_losses.append(running_loss/len(train_loader))\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {train_losses[-1]:.4f}\")\n",
        "\n",
        "    return train_losses\n"
      ],
      "metadata": {
        "id": "_KKQOsNxytL7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, loader, num_classes):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "    # Accuracy\n",
        "    acc = np.mean(np.array(all_preds) == np.array(all_labels))\n",
        "\n",
        "    # Top-3 Accuracy (for flowers)\n",
        "    if num_classes > 2:\n",
        "        top3 = accuracy(torch.tensor(all_probs),\n",
        "                        torch.tensor(all_labels),\n",
        "                        task=\"multiclass\",\n",
        "                        num_classes=num_classes,\n",
        "                        top_k=3)\n",
        "    else:\n",
        "        top3 = None\n",
        "\n",
        "    # F1 and Precision/Recall\n",
        "    report = classification_report(all_labels, all_preds, output_dict=True)\n",
        "    macro_f1 = report['macro avg']['f1-score']\n",
        "    balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    return acc, top3, macro_f1, balanced_acc, cm, all_probs, all_labels\n"
      ],
      "metadata": {
        "id": "N41XQbayytIy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb9syDN9zxmV",
        "outputId": "539aa14c-7313-4777-9b2e-a8717c2b8785"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_classes_flower = len(flower_train.classes)\n",
        "\n",
        "resnet_flower = get_resnet(num_classes_flower)\n",
        "efficient_flower = get_efficientnet(num_classes_flower)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_resnet = optim.Adam(resnet_flower.parameters(), lr=0.001)\n",
        "optimizer_eff = optim.Adam(efficient_flower.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Training ResNet on Flowers\")\n",
        "train_model(resnet_flower, flower_loader_os, flower_loader_os, criterion, optimizer_resnet)\n",
        "\n",
        "print(\"Training EfficientNet on Flowers\")\n",
        "train_model(efficient_flower, flower_loader_os, flower_loader_os, criterion, optimizer_eff)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFHrQzSqytFj",
        "outputId": "35876f00-2f51-4b70-dc35-0b54f56ed8fa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 178MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 136MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ResNet on Flowers\n",
            "Epoch [1/5], Loss: 0.6722\n",
            "Epoch [2/5], Loss: 0.4964\n",
            "Epoch [3/5], Loss: 0.4067\n",
            "Epoch [4/5], Loss: 0.3484\n",
            "Epoch [5/5], Loss: 0.3116\n",
            "Training EfficientNet on Flowers\n",
            "Epoch [1/5], Loss: 0.4390\n",
            "Epoch [2/5], Loss: 0.2398\n",
            "Epoch [3/5], Loss: 0.2172\n",
            "Epoch [4/5], Loss: 0.1781\n",
            "Epoch [5/5], Loss: 0.1597\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4390007338038197,\n",
              " 0.23982654048336877,\n",
              " 0.21716798877826443,\n",
              " 0.1781011524023833,\n",
              " 0.1596528406565388]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(efficient_flower.state_dict(),\n",
        "           f\"{save_path}/efficientnet_flower.pth\")\n",
        "\n",
        "torch.save(resnet_flower.state_dict(),\n",
        "           f\"{save_path}/resnet_flower.pth\")\n",
        "\n",
        "print(\"Models saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBd5z8ag6Vq-",
        "outputId": "4d373177-842f-4e6c-ecef-b1ffa7984ce1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes_chest = len(chest_train.classes)\n",
        "\n",
        "resnet_chest = get_resnet(num_classes_chest)\n",
        "efficient_chest = get_efficientnet(num_classes_chest)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_resnet = optim.Adam(resnet_chest.parameters(), lr=0.001)\n",
        "optimizer_eff = optim.Adam(efficient_chest.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Training ResNet on Chest\")\n",
        "train_model(resnet_chest, chest_loader_os, chest_loader_os, criterion, optimizer_resnet)\n",
        "\n",
        "print(\"Training EfficientNet on Chest\")\n",
        "train_model(efficient_chest, chest_loader_os, chest_loader_os, criterion, optimizer_eff)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ruz3omHeytCV",
        "outputId": "73722431-d11d-415b-98f3-c6fdc8dc665b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ResNet on Chest\n",
            "Epoch [1/5], Loss: 0.1493\n",
            "Epoch [2/5], Loss: 0.0845\n",
            "Epoch [3/5], Loss: 0.0797\n",
            "Epoch [4/5], Loss: 0.0646\n",
            "Epoch [5/5], Loss: 0.0668\n",
            "Training EfficientNet on Chest\n",
            "Epoch [1/5], Loss: 0.1440\n",
            "Epoch [2/5], Loss: 0.0695\n",
            "Epoch [3/5], Loss: 0.0591\n",
            "Epoch [4/5], Loss: 0.0426\n",
            "Epoch [5/5], Loss: 0.0498\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1439617920918333,\n",
              " 0.06954269916207695,\n",
              " 0.05907659520369389,\n",
              " 0.0425636335551036,\n",
              " 0.04978617959528336]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(efficient_chest.state_dict(),\n",
        "           f\"{save_path}/efficientnet_chest.pth\")\n",
        "\n",
        "torch.save(resnet_chest.state_dict(),\n",
        "           f\"{save_path}/resnet_chest.pth\")\n",
        "\n",
        "print(\"Models saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yntcSExM6Sa6",
        "outputId": "d9ba70ed-a833-423c-edeb-af3408173cf1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_r, top3_r, f1_r, bal_r, cm_r, probs_r, labels_r = evaluate_model(\n",
        "    resnet_flower, flower_loader, num_classes_flower)\n",
        "\n",
        "acc_e, top3_e, f1_e, bal_e, cm_e, probs_e, labels_e = evaluate_model(\n",
        "    efficient_flower, flower_loader, num_classes_flower)\n",
        "\n",
        "print(\"ResNet Flower Accuracy:\", acc_r)\n",
        "print(\"EfficientNet Flower Accuracy:\", acc_e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZufZVeANj59h",
        "outputId": "675bd0aa-6aea-48ab-c898-c0f90905a2f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1306553613.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  top3 = accuracy(torch.tensor(all_probs),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet Flower Accuracy: 0.87607134584202\n",
            "EfficientNet Flower Accuracy: 0.9722029186935371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WrQWX1RpUM9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ws_nLaVNUM6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9J8-DtTGy_xN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}